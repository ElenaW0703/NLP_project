{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977885c3",
   "metadata": {},
   "source": [
    "author:   \n",
    "Zhaojie Chen (zc153)  \n",
    "TJ Tang (tt238)   \n",
    "Elena Wang (xnw3)   \n",
    "Chihui Shao (cs662)    \n",
    "Qin He (qh58)   \n",
    "Mingxuan Wang (mw446) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb7dbe8-0c18-4a87-ad4d-3f327db865ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/student/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import method\n",
    "import evaluation \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428c32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods we are considering\n",
    "methods_list = [\"Luhn\",\"KLSum\",\"LSA\",\"textRank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bf6f3",
   "metadata": {},
   "source": [
    "### Evaluation Metrics (ROUGE metric)  \n",
    "source: https://github.com/Diego999/py-rouge#readme  \n",
    "https://stackoverflow.com/questions/9879276/how-do-i-evaluate-a-text-summarization-tool    \n",
    "https://en.wikipedia.org/wiki/ROUGE_(metric)  \n",
    "https://www.ccs.neu.edu/home/vip/teach/DMcourse/5_topicmodel_summ/notes_slides/What-is-ROUGE.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670941b5",
   "metadata": {},
   "source": [
    "ROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics that compare an automatically produced summary against human-produced summary (references). Here are some metrics in ROUGE.\n",
    "- ROUGE-N (N=1,2,...): overlap of N-grams between the system and reference summaries. (For example, ROUGE-1 refers to the overlap of unigram (i.e. each word).)\n",
    "- ROUGE-L: Longest Common Subsequence (LCS) based statistics. Longest common subsequence problem considers sentence level structure similarity naturally and identifies longest co-occurring in sequence n-grams automatically.\n",
    "\n",
    "ROUGE will measure precision (P), recall (R), and F-score (F). In ROUGE, precision measures how much of the automatically produced summary in relevant or needed, which is computed as the percentage of overlapping words in the machine generated summary.  On the other hand, recall means how much of the reference summary is the automatically produced summary recovering, which can be computed as the percentage of overlapping words in the reference summary. F-score combines P and R together, and it calculated as $\\frac{2*P*R}{P+R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0df85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare by ROUGE\n",
    "def compare_methods_rouge(origin_file,ref_file,sentence_count=5):\n",
    "    # machine summary\n",
    "    me = method.Method(sentence_count, file = origin_file)\n",
    "    hypothesis_1 = me.luhn()\n",
    "    hypothesis_2 = me.klsum()\n",
    "    hypothesis_3 = me.lsa()\n",
    "    hypothesis_4 = me.textRank()\n",
    "    # read reference text\n",
    "    with open(ref_file, 'r') as file: \n",
    "        reference_1 = file.read().replace('\\n','') # human summary\n",
    "    luhn_auto = pd.DataFrame(evaluation.rouge_eval(hypothesis_1,reference_1)).style.hide_index().data\n",
    "    klsum_auto = pd.DataFrame(evaluation.rouge_eval(hypothesis_2,reference_1)).style.hide_index().data\n",
    "    lsa_auto = pd.DataFrame(evaluation.rouge_eval(hypothesis_3,reference_1)).style.hide_index().data\n",
    "    textrank_auto = pd.DataFrame(evaluation.rouge_eval(hypothesis_4,reference_1)).style.hide_index().data\n",
    "    compare = pd.concat(\n",
    "        [luhn_auto,klsum_auto,lsa_auto,textrank_auto],\n",
    "        keys=methods_list,\n",
    "        axis=1\n",
    "    )\n",
    "    compare.insert(0,column=\"Metric\",value=[\"ROUGE-1\",\"ROUGE-L\"])\n",
    "    return(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9765bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare by length\n",
    "def compare_methods_charcount(file,sentence_count=5):\n",
    "    # machine summary\n",
    "    me = method.Method(sentence_count, file = file)\n",
    "    return({\"luhn\":len(me.luhn()),\"klsum\":len(me.klsum()),\"lsa\":len(me.lsa()),\"textRank\":len(me.textRank())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1908553",
   "metadata": {},
   "source": [
    "### Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2520bdb",
   "metadata": {},
   "source": [
    "#### News \n",
    "source: https://www.kaggle.com/datasets/sunnysai12345/news-summary?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423fc013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 272</th>\n",
       "      <th>Unnamed: 273</th>\n",
       "      <th>Unnamed: 274</th>\n",
       "      <th>Unnamed: 275</th>\n",
       "      <th>Unnamed: 276</th>\n",
       "      <th>Unnamed: 277</th>\n",
       "      <th>Unnamed: 278</th>\n",
       "      <th>Unnamed: 279</th>\n",
       "      <th>Unnamed: 280</th>\n",
       "      <th>Unnamed: 281</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                  date  \\\n",
       "0  Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "\n",
       "                                               ctext Unnamed: 6 Unnamed: 7  \\\n",
       "0  The Daman and Diu administration on Wednesday ...        NaN        NaN   \n",
       "\n",
       "  Unnamed: 8 Unnamed: 9  ... Unnamed: 272 Unnamed: 273 Unnamed: 274  \\\n",
       "0        NaN        NaN  ...          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 275 Unnamed: 276 Unnamed: 277 Unnamed: 278 Unnamed: 279  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 280 Unnamed: 281  \n",
       "0          NaN          NaN  \n",
       "\n",
       "[1 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/48067514/utf-8-codec-cant-decode-byte-0xa0-in-position-4276-invalid-start-byte\n",
    "news = pd.read_csv(\"data/news_summary.csv\",encoding='windows-1252')\n",
    "news.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7ba864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Metric   Luhn                KLSum                  LSA                \\\n",
      "                P      R      F      P      R      F      P      R      F   \n",
      "0  ROUGE-1  28.57  50.00  36.36  50.96  88.33  64.63  50.96  88.33  64.63   \n",
      "1  ROUGE-L  17.54  27.96  21.55  32.50  51.41  39.83  32.50  51.41  39.83   \n",
      "\n",
      "  textRank                \n",
      "         P      R      F  \n",
      "0    46.67  81.67  59.39  \n",
      "1    32.25  51.41  39.63  \n",
      "    Metric   Luhn                KLSum                  LSA                \\\n",
      "                P      R      F      P      R      F      P      R      F   \n",
      "0  ROUGE-1  17.65  28.57  21.82  14.02  23.81  17.65  19.23  31.75  23.95   \n",
      "1  ROUGE-L  14.44  21.57  17.30  11.52  17.91  14.02  13.01  19.76  15.69   \n",
      "\n",
      "  textRank                \n",
      "         P      R      F  \n",
      "0    18.45  30.16  22.89  \n",
      "1    16.67  25.11  20.04  \n",
      "    Metric   Luhn                KLSum                  LSA                \\\n",
      "                P      R      F      P      R      F      P      R      F   \n",
      "0  ROUGE-1  27.10  48.33  34.73  22.45  36.67  27.85  33.33  60.00  42.86   \n",
      "1  ROUGE-L  20.52  33.24  25.38  16.16  24.32  19.42  27.56  44.98  34.18   \n",
      "\n",
      "  textRank                \n",
      "         P      R      F  \n",
      "0    30.56  55.00  39.29  \n",
      "1    23.50  38.36  29.15  \n",
      "    Metric   Luhn                KLSum                  LSA                \\\n",
      "                P      R      F      P      R      F      P      R      F   \n",
      "0  ROUGE-1  16.50  26.56  20.36  38.16  45.31  41.43  28.70  48.44  36.05   \n",
      "1  ROUGE-L  16.67  24.78  19.93  34.24  39.51  36.69  19.30  29.85  23.44   \n",
      "\n",
      "  textRank                \n",
      "         P      R      F  \n",
      "0    18.69  31.25  23.39  \n",
      "1    17.26  26.49  20.91  \n",
      "    Metric   Luhn                KLSum                  LSA                \\\n",
      "                P      R      F      P      R      F      P      R      F   \n",
      "0  ROUGE-1  25.00  43.33  31.71  37.50  65.00  47.56  45.10  76.67  56.79   \n",
      "1  ROUGE-L  16.54  26.15  20.26  39.39  62.29  48.26  45.84  71.33  55.81   \n",
      "\n",
      "  textRank                \n",
      "         P      R      F  \n",
      "0    21.15  36.67  26.83  \n",
      "1    13.01  20.58  15.94  \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    news_text = news[\"ctext\"][i]\n",
    "    news_ref = news[\"text\"][i]\n",
    "    me = method.Method(5, text = news_text)\n",
    "    luhn_news = pd.DataFrame(evaluation.rouge_eval(me.luhn(),news_ref)).style.hide_index().data\n",
    "    klsum_news = pd.DataFrame(evaluation.rouge_eval(me.klsum(),news_ref)).style.hide_index().data\n",
    "    lsa_news = pd.DataFrame(evaluation.rouge_eval(me.lsa(),news_ref)).style.hide_index().data\n",
    "    textrank_news = pd.DataFrame(evaluation.rouge_eval(me.textRank(),news_ref)).style.hide_index().data\n",
    "    news_compare = pd.concat(\n",
    "        [luhn_news,klsum_news,lsa_news,textrank_news],\n",
    "        keys=methods_list,\n",
    "        axis=1\n",
    "    )\n",
    "    news_compare.insert(0,column=\"Metric\",value=[\"ROUGE-1\",\"ROUGE-L\"])\n",
    "    print(news_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0368603",
   "metadata": {},
   "source": [
    "#### Essays/Blog Articles\n",
    "\n",
    "source: https://blog.hypeinnovation.com/innovation-management-10-most-popular-articles-2016  \n",
    "https://blog.hypeinnovation.com/the-single-most-important-kpi-for-building-innovation-muscle?hsCtaTracking=c5fc5fb8-3611-4e97-ac7b-5f347e517f48%7Cbb4a45cd-6c6a-4478-ade4-0f7fd322dbe0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2888134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Luhn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KLSum</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LSA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">textRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>14.29</td>\n",
       "      <td>27.78</td>\n",
       "      <td>18.87</td>\n",
       "      <td>24.04</td>\n",
       "      <td>46.30</td>\n",
       "      <td>31.65</td>\n",
       "      <td>18.75</td>\n",
       "      <td>33.33</td>\n",
       "      <td>24.00</td>\n",
       "      <td>19.10</td>\n",
       "      <td>31.48</td>\n",
       "      <td>23.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>12.91</td>\n",
       "      <td>22.47</td>\n",
       "      <td>16.40</td>\n",
       "      <td>26.36</td>\n",
       "      <td>45.52</td>\n",
       "      <td>33.39</td>\n",
       "      <td>15.19</td>\n",
       "      <td>24.53</td>\n",
       "      <td>18.76</td>\n",
       "      <td>14.82</td>\n",
       "      <td>22.47</td>\n",
       "      <td>17.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric   Luhn                KLSum                  LSA                \\\n",
       "                P      R      F      P      R      F      P      R      F   \n",
       "0  ROUGE-1  14.29  27.78  18.87  24.04  46.30  31.65  18.75  33.33  24.00   \n",
       "1  ROUGE-L  12.91  22.47  16.40  26.36  45.52  33.39  15.19  24.53  18.76   \n",
       "\n",
       "  textRank                \n",
       "         P      R      F  \n",
       "0    19.10  31.48  23.78  \n",
       "1    14.82  22.47  17.86  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_methods_rouge(\"data/innovation.txt\",\"data/innovation_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b3c57",
   "metadata": {},
   "source": [
    "#### Novel (A Tale of Two Cities)\n",
    "\n",
    "source: https://www.online-literature.com/dickens/twocities/1/  \n",
    "\n",
    "SparkNotes editors. \"A Tale of Two Cities Summary: Chapter 1: The Period\" SparkNotes.com, SparkNotes LLC, 2005,  \n",
    "https://www.sparknotes.com/lit/a-tale-of-two-cities/section2/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f134cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Luhn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KLSum</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LSA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">textRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>28.16</td>\n",
       "      <td>28.57</td>\n",
       "      <td>25.96</td>\n",
       "      <td>26.21</td>\n",
       "      <td>26.09</td>\n",
       "      <td>25.96</td>\n",
       "      <td>26.21</td>\n",
       "      <td>26.09</td>\n",
       "      <td>31.68</td>\n",
       "      <td>31.07</td>\n",
       "      <td>31.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>22.84</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.56</td>\n",
       "      <td>23.18</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.28</td>\n",
       "      <td>19.92</td>\n",
       "      <td>20.08</td>\n",
       "      <td>20.00</td>\n",
       "      <td>29.14</td>\n",
       "      <td>28.67</td>\n",
       "      <td>28.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric   Luhn                KLSum                  LSA                \\\n",
       "                P      R      F      P      R      F      P      R      F   \n",
       "0  ROUGE-1  29.00  28.16  28.57  25.96  26.21  26.09  25.96  26.21  26.09   \n",
       "1  ROUGE-L  22.84  22.28  22.56  23.18  23.37  23.28  19.92  20.08  20.00   \n",
       "\n",
       "  textRank                \n",
       "         P      R      F  \n",
       "0    31.68  31.07  31.37  \n",
       "1    29.14  28.67  28.90  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Tale of Two Cities Chapter 1\n",
    "compare_methods_rouge(\"data/a-tale-of-two-cities_c1.txt\",\"data/summary_c1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a31e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'luhn': 3588, 'klsum': 2200, 'lsa': 1047, 'textRank': 1241}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_methods_charcount(\"data/a-tale-of-two-cities_c1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98de1b3",
   "metadata": {},
   "source": [
    "#### Novel (The Five Orange Pips)\n",
    "\n",
    "source: https://sherlock-holm.es/ascii/  \n",
    "https://en.wikipedia.org/wiki/The_Five_Orange_Pips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3707e77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Luhn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KLSum</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LSA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">textRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>29.70</td>\n",
       "      <td>29.41</td>\n",
       "      <td>29.56</td>\n",
       "      <td>15.69</td>\n",
       "      <td>15.69</td>\n",
       "      <td>15.69</td>\n",
       "      <td>22.11</td>\n",
       "      <td>20.59</td>\n",
       "      <td>21.32</td>\n",
       "      <td>28.71</td>\n",
       "      <td>28.43</td>\n",
       "      <td>28.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>19.27</td>\n",
       "      <td>19.11</td>\n",
       "      <td>19.19</td>\n",
       "      <td>15.63</td>\n",
       "      <td>15.63</td>\n",
       "      <td>15.63</td>\n",
       "      <td>17.83</td>\n",
       "      <td>16.81</td>\n",
       "      <td>17.30</td>\n",
       "      <td>19.27</td>\n",
       "      <td>19.11</td>\n",
       "      <td>19.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric   Luhn                KLSum                  LSA                \\\n",
       "                P      R      F      P      R      F      P      R      F   \n",
       "0  ROUGE-1  29.70  29.41  29.56  15.69  15.69  15.69  22.11  20.59  21.32   \n",
       "1  ROUGE-L  19.27  19.11  19.19  15.63  15.63  15.63  17.83  16.81  17.30   \n",
       "\n",
       "  textRank                \n",
       "         P      R      F  \n",
       "0    28.71  28.43  28.57  \n",
       "1    19.27  19.11  19.19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Five Orange Pips\n",
    "compare_methods_rouge(\"data/orange.txt\",\"data/summary_orange.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82c56b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'luhn': 1584, 'klsum': 1615, 'lsa': 503, 'textRank': 1121}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_methods_charcount(\"data/orange.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f103d",
   "metadata": {},
   "source": [
    "#### Novel (1984)\n",
    "\n",
    "source:  \n",
    "https://www.george-orwell.org/1984/0.html  \n",
    "SparkNotes editors. “1984 Summary: Chapter 1.” SparkNotes.com, SparkNotes LLC, 2005, https://www.sparknotes.com/lit/1984/section1/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065fb774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Luhn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KLSum</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LSA</th>\n",
       "      <th colspan=\"3\" halign=\"left\">textRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>22.77</td>\n",
       "      <td>22.55</td>\n",
       "      <td>22.66</td>\n",
       "      <td>27.72</td>\n",
       "      <td>27.45</td>\n",
       "      <td>27.59</td>\n",
       "      <td>31.43</td>\n",
       "      <td>32.35</td>\n",
       "      <td>31.88</td>\n",
       "      <td>26.92</td>\n",
       "      <td>27.45</td>\n",
       "      <td>27.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>19.27</td>\n",
       "      <td>19.11</td>\n",
       "      <td>19.19</td>\n",
       "      <td>21.54</td>\n",
       "      <td>21.36</td>\n",
       "      <td>21.45</td>\n",
       "      <td>19.76</td>\n",
       "      <td>20.24</td>\n",
       "      <td>20.00</td>\n",
       "      <td>19.92</td>\n",
       "      <td>20.24</td>\n",
       "      <td>20.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric   Luhn                KLSum                  LSA                \\\n",
       "                P      R      F      P      R      F      P      R      F   \n",
       "0  ROUGE-1  22.77  22.55  22.66  27.72  27.45  27.59  31.43  32.35  31.88   \n",
       "1  ROUGE-L  19.27  19.11  19.19  21.54  21.36  21.45  19.76  20.24  20.00   \n",
       "\n",
       "  textRank                \n",
       "         P      R      F  \n",
       "0    26.92  27.45  27.18  \n",
       "1    19.92  20.24  20.08  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1984\n",
    "compare_methods_rouge(\"data/1984.txt\",\"data/1984_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f370ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'luhn': 2503, 'klsum': 2118, 'lsa': 802, 'textRank': 899}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_methods_charcount(\"data/1984.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
